
# ğŸ“ Project Setup and Usage Guide

## ğŸ› ï¸ Setup Instructions

To set up the environment and prepare the project, run the following commands:

### ğŸ§‘â€ğŸ’» Run the Setup Script
```shell
# Remove all __pycache__ directories and .egg-info files recursively
find . -name "__pycache__" -type d -exec rm -rf {} + -o -name "*.egg-info" -type d -exec rm -rf {} +

# Make the setup script executable and run it
chmod +x ./setup_vie.sh
./setup_vie.sh
```

---

## ğŸ“œ Requirements

- All the vie modules are tested on **Python 3.10.15**
  - robokit
  - gdino
  - samv2
  - hamer

---

https://github.com/user-attachments/assets/015088f9-7031-44b9-b1b4-f4ea75043109

## ğŸ”§ Tools

### 1. ğŸ¤– Testing GDINO Prompts
To test GDINO with a text prompt:
```shell
cp scripts/test_gdino_prompts.py .
python test_gdino_prompts.py --input_dir ./imgs/test/000100/rgb --text_prompt <obj-text-prompt> --infer_first_only
# The output will be saved in: /imgs/test/000100/out/gdino/<obj_text_prompt>
```

### 2. ğŸ” Testing GDINO + SAMv2
To use GDINO and SAMv2 for object bounding box detection and tracking in video frames:
```shell
cp scripts/test_gdino_samv2.py .
python test_gdino_samv2.py --input_dir ./imgs/test/000100/rgb --text_prompt <obj-text-prompt> --save_interval=1
# Output saved in:
# ../imgs/test/000100/out/samv2/<obj_text_prompt>/obj_masks - object mask
# ../imgs/test/000100/out/samv2/<obj_text_prompt>/masks_traj_overlayed - Trajectory + mask overlay + initial object bbox
```

### 3. âœ‹ Extracting Right/Left Hand BBoxes and Meshes
![vie-hand](../media/imgs/vie-hand.png)

To extract right(1) / left(0) hand bounding boxes and 3D meshes
- Assuming only one person in the scene
- <red style="color:red">Frames containing atleast one hand will be only saved in `out/hamer/model`</red>
```shell
cd hamer
python extract_hand_bboxes_and_meshes.py --input_dir "../imgs/test/000100/rgb"

# Output will be saved in:
# ../imgs/test/000100/out/hamer/extra_plots - For visualization and debugging
# ../imgs/test/000100/out/hamer/scene - RGB scene point cloud
# ../imgs/test/000100/out/hamer/model - HAMER output, including mano params
# ../imgs/test/000100/out/hamer/3dhand - 3D hand mesh aligned with scene point cloud
```

### After data processing, following would be the dir structure
```
â”œâ”€â”€ data_captured
    â”œâ”€â”€ <task-name>-1/
        â”œâ”€â”€ rgb/
            â”œâ”€â”€ 000000.jpg
            â”œâ”€â”€ 000001.jpg
            â””â”€â”€ ...
        â”œâ”€â”€ depth/
            â”œâ”€â”€ 000000.png
            â”œâ”€â”€ 000001.png
            â””â”€â”€ ...
        â”œâ”€â”€ pose/
            â”œâ”€â”€ 000000.npz
            â”œâ”€â”€ 000001.npz
            â””â”€â”€ ...
        â””â”€â”€ out/
            â”œâ”€â”€ gdino
                â”œâ”€â”€ <text-prompt>
            â”œâ”€â”€ samv2
                â”œâ”€â”€ <text-prompt>
                â”œâ”€â”€ obj_masks
                â””â”€â”€ masks_traj_overlayed
            â””â”€â”€ hamer
                â”œâ”€â”€ extra_plots
                    â”œâ”€â”€ 000000.npz
                    â”œâ”€â”€ 000000.npz
                    â”œâ”€â”€ 000000.npz
                â”œâ”€â”€ scene
                    â”œâ”€â”€ 000000.ply
                    â”œâ”€â”€ 000001.ply
                    â””â”€â”€ ...
                â”œâ”€â”€ model
                    â”œâ”€â”€ 000000.npz
                    â”œâ”€â”€ 000001.npz
                    â””â”€â”€ ...
                â””â”€â”€ 3dhand
                    â”œâ”€â”€ 000000.ply
                    â”œâ”€â”€ 000001.ply
                    â””â”€â”€ ...
        
    â”œâ”€â”€ <task-name>-2/
    â””â”€â”€ <task-name>-.../
```

---

## ğŸ™ Acknowledgments

This project utilizes the following resources:

- [HPHB](https://github.com/IRVLUTD/HumanPoseHandBoxes)
- [GDINO + SamV2](https://github.com/IRVLUTD/robokit)
---
